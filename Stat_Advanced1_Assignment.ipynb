{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics Advance Part 1 - Solved Assignment"
      ],
      "metadata": {
        "id": "intro_heading"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theoretical Questions"
      ],
      "metadata": {
        "id": "theory_heading"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1:** What is a random variable in probability theory?"
      ],
      "metadata": {
        "id": "t_q_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A1:** A **random variable** is a variable whose value is a numerical outcome of a random phenomenon. It acts as a function that maps the outcomes of a random process to numerical quantities. For example, in a coin toss, the random variable could be 0 for tails and 1 for heads."
      ],
      "metadata": {
        "id": "t_a_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2:** What are the types of random variables?"
      ],
      "metadata": {
        "id": "t_q_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A2:** There are two main types of random variables:\n",
        "\n",
        "1.  **Discrete Random Variable:** A variable that can take on a finite or countably infinite number of distinct values. Examples include the outcome of a dice roll (1, 2, 3, 4, 5, 6) or the number of defective items in a batch.\n",
        "2.  **Continuous Random Variable:** A variable that can take on any value within a given range or interval. Examples include the height of a person, the temperature of a room, or the time it takes to complete a task."
      ],
      "metadata": {
        "id": "t_a_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3:** What is the difference between discrete and continuous distributions?"
      ],
      "metadata": {
        "id": "t_q_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A3:** The primary difference lies in the type of random variable they describe:\n",
        "\n",
        "-   **Discrete Distribution:** Describes the probability of occurrence for each possible value of a discrete random variable. It is defined by a **Probability Mass Function (PMF)**, which gives the probability $P(X=x)$ for each distinct value $x$. The sum of all probabilities is 1.\n",
        "-   **Continuous Distribution:** Describes the probabilities for a continuous random variable. It is defined by a **Probability Density Function (PDF)**. For a continuous variable, the probability of it taking on any specific value is zero ($P(X=x) = 0$). Instead, probability is defined over a range, calculated as the area under the PDF curve for that range. The total area under the curve is 1."
      ],
      "metadata": {
        "id": "t_a_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4:** What are probability distribution functions (PDF)?"
      ],
      "metadata": {
        "id": "t_q_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A4:** A **Probability Density Function (PDF)**, or more accurately, a probability distribution, is a mathematical function that describes the likelihood of different possible values of a random variable. For a **discrete** variable, this is the **Probability Mass Function (PMF)**, which gives the probability of each discrete outcome. For a **continuous** variable, this is the **Probability Density Function (PDF)**, where the area under the curve between two points gives the probability that the variable falls within that interval."
      ],
      "metadata": {
        "id": "t_a_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5:** How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?"
      ],
      "metadata": {
        "id": "t_q_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A5:** The key difference is what they represent:\n",
        "\n",
        "-   **Probability Density Function (PDF):** Describes the *relative likelihood* or probability density for a random variable to take on a given value. For a continuous variable, the value of the PDF at a point is not a probability itself.\n",
        "-   **Cumulative Distribution Function (CDF):** Describes the *cumulative probability* that a random variable $X$ will take a value less than or equal to a specific value $x$. It is denoted as $F(x) = P(X \\leq x)$. The CDF is an accumulation of probability, so its value ranges from 0 to 1."
      ],
      "metadata": {
        "id": "t_a_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6:** What is a discrete uniform distribution?"
      ],
      "metadata": {
        "id": "t_q_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A6:** A **discrete uniform distribution** is a probability distribution where a finite number of outcomes are equally likely. A classic example is the roll of a fair six-sided die, where each outcome {1, 2, 3, 4, 5, 6} has an equal probability of $1/6$."
      ],
      "metadata": {
        "id": "t_a_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7:** What are the key properties of a Bernoulli distribution?"
      ],
      "metadata": {
        "id": "t_q_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A7:** A **Bernoulli distribution** models a single trial with only two possible outcomes, conventionally labeled as \"success\" and \"failure\". Its key properties are:\n",
        "\n",
        "1.  **Single Trial:** The experiment is performed only once.\n",
        "2.  **Two Outcomes:** There are only two possible outcomes (e.g., heads/tails, yes/no).\n",
        "3.  **Probability:** The probability of success is denoted by $p$, and the probability of failure is $1-p$."
      ],
      "metadata": {
        "id": "t_a_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8:** What is the binomial distribution, and how is it used in probability?"
      ],
      "metadata": {
        "id": "t_q_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A8:** The **binomial distribution** is a discrete probability distribution that models the number of successes ($k$) in a fixed number of independent Bernoulli trials ($n$).\n",
        "\n",
        "It is defined by two parameters:\n",
        "-   $n$: the number of trials.\n",
        "-   $p$: the probability of success on a single trial.\n",
        "\n",
        "It is used to calculate the probability of getting exactly $k$ successes in $n$ trials, for example, the probability of getting exactly 3 heads in 5 coin tosses."
      ],
      "metadata": {
        "id": "t_a_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9:** What is the Poisson distribution and where is it applied?"
      ],
      "metadata": {
        "id": "t_q_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A9:** The **Poisson distribution** is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space, given that these events occur with a known constant mean rate and independently of the time since the last event.\n",
        "\n",
        "It is defined by a single parameter:\n",
        "-   $\\lambda$ (lambda): the average number of events in the interval.\n",
        "\n",
        "**Applications:**\n",
        "-   Number of phone calls received by a call center per hour.\n",
        "-   Number of typos on a page.\n",
        "-   Number of radioactive decay events in a given time period."
      ],
      "metadata": {
        "id": "t_a_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10:** What is a continuous uniform distribution?"
      ],
      "metadata": {
        "id": "t_q_10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A10:** A **continuous uniform distribution** (or rectangular distribution) is a probability distribution where all outcomes within a certain range $[a, b]$ are equally likely. The PDF is constant within the interval $[a, b]$ and zero everywhere else. An example is a random number generator that produces numbers between 0 and 1, where any number has an equal chance of being generated."
      ],
      "metadata": {
        "id": "t_a_10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11:** What are the characteristics of a normal distribution?"
      ],
      "metadata": {
        "id": "t_q_11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A11:** The **normal distribution** (or Gaussian distribution) has the following key characteristics:\n",
        "\n",
        "1.  **Bell-Shaped Curve:** The graph of its PDF is a symmetric, bell-shaped curve.\n",
        "2.  **Symmetry:** It is symmetric about its mean.\n",
        "3.  **Mean, Median, and Mode:** The mean, median, and mode are all equal and located at the center of the distribution.\n",
        "4.  **Parameters:** It is fully described by its mean ($\\mu$) and standard deviation ($\\sigma$).\n",
        "5.  **Empirical Rule:** Approximately 68% of the data falls within one standard deviation of the mean, 95% within two, and 99.7% within three."
      ],
      "metadata": {
        "id": "t_a_11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12:** What is the standard normal distribution, and why is it important?"
      ],
      "metadata": {
        "id": "t_q_12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A12:** The **standard normal distribution** is a special case of the normal distribution with a **mean ($\\mu$) of 0** and a **standard deviation ($\\sigma$) of 1**.\n",
        "\n",
        "**Importance:** It is crucial because any normal distribution can be transformed into the standard normal distribution by converting its values into **Z-scores**. This process, called standardization, allows us to:\n",
        "-   Compare values from different normally distributed datasets.\n",
        "-   Easily calculate probabilities using a standard table (Z-table) or software, without needing a separate table for every possible combination of mean and standard deviation."
      ],
      "metadata": {
        "id": "t_a_12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13:** What is the Central Limit Theorem (CLT), and why is it critical in statistics?"
      ],
      "metadata": {
        "id": "t_q_13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A13:** The **Central Limit Theorem (CLT)** is a fundamental theorem in statistics which states that the distribution of sample means of a large number of samples taken from a population will be approximately normally distributed, **regardless of the original population's distribution**, as long as the sample size is sufficiently large (typically $n > 30$).\n",
        "\n",
        "It is critical because it allows us to use statistical methods that assume a normal distribution (like hypothesis testing and confidence intervals) for the sample mean, even if we don't know the shape of the population's distribution."
      ],
      "metadata": {
        "id": "t_a_13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14:** How does the Central Limit Theorem relate to the normal distribution?"
      ],
      "metadata": {
        "id": "t_q_14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A14:** The Central Limit Theorem provides the theoretical foundation that connects any distribution to the normal distribution. It guarantees that the **sampling distribution of the sample mean will approximate a normal distribution** as the sample size increases. This relationship is powerful because it allows statisticians to make inferences about population parameters using the well-understood properties of the normal distribution, without needing to know the population's actual distribution."
      ],
      "metadata": {
        "id": "t_a_14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15:** What is the application of Z statistics in hypothesis testing?"
      ],
      "metadata": {
        "id": "t_q_15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A15:** The **Z-statistic** (or Z-test) is used in hypothesis testing to determine whether two population means are different when the variances are known and the sample size is large. It tests a null hypothesis by comparing the sample statistic (e.g., sample mean) to the population parameter. The Z-statistic measures how many standard errors the sample mean is away from the population mean under the null hypothesis. If this value is extreme (falling in the rejection region of the standard normal distribution), we reject the null hypothesis."
      ],
      "metadata": {
        "id": "t_a_15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16:** How do you calculate a Z-score, and what does it represent?"
      ],
      "metadata": {
        "id": "t_q_16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A16:** A **Z-score** is calculated using the formula:\n",
        "$$ Z = \\frac{X - \\mu}{\\sigma} $$\n",
        "Where:\n",
        "-   $X$ is the data point.\n",
        "-   $\\mu$ is the population mean.\n",
        "-   $\\sigma$ is the population standard deviation.\n",
        "\n",
        "A Z-score represents the **number of standard deviations a data point is away from the mean**. A positive Z-score indicates the data point is above the mean, while a negative Z-score indicates it is below the mean. A Z-score of 0 means the data point is exactly at the mean."
      ],
      "metadata": {
        "id": "t_a_16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17:** What are point estimates and interval estimates in statistics?"
      ],
      "metadata": {
        "id": "t_q_17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A17:**\n",
        "-   A **Point Estimate** is a single value (a statistic) used to estimate an unknown population parameter. For example, the sample mean $(\\bar{x})$ is a point estimate of the population mean $(\\mu)$.\n",
        "\n",
        "-   An **Interval Estimate** is a range of values used to estimate an unknown population parameter. It gives a range within which the true parameter is likely to lie. The most common type of interval estimate is a **confidence interval**."
      ],
      "metadata": {
        "id": "t_a_17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18:** What is the significance of confidence intervals in statistical analysis?"
      ],
      "metadata": {
        "id": "t_q_18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A18:** The significance of **confidence intervals (CIs)** lies in their ability to quantify the uncertainty associated with a point estimate. Instead of providing just one number, a CI provides a range of plausible values for the population parameter.\n",
        "\n",
        "For example, a 95% confidence interval for a mean suggests that if we were to repeat our sampling process many times, 95% of the calculated intervals would contain the true population mean. It provides a measure of both the location and precision of our estimate."
      ],
      "metadata": {
        "id": "t_a_18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19:** What is the relationship between a Z-score and a confidence interval?"
      ],
      "metadata": {
        "id": "t_q_19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A19:** Z-scores are used to construct confidence intervals. The formula for a confidence interval for a population mean is:\n",
        "$$ CI = \\text{Point Estimate} \\pm (\\text{Critical Value} \\times \\text{Standard Error}) $$\n",
        "$$ CI = \\bar{x} \\pm (Z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}) $$\n",
        "The **critical value** ($Z_{\\alpha/2}$) is a Z-score that corresponds to the desired confidence level. For example, for a 95% confidence interval, the critical Z-score is 1.96, which marks the boundaries containing the central 95% of the standard normal distribution."
      ],
      "metadata": {
        "id": "t_a_19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20:** How are Z-scores used to compare different distributions?"
      ],
      "metadata": {
        "id": "t_q_20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A20:** Z-scores standardize data points from different normal distributions, allowing for a direct comparison on a common scale. By converting values from different datasets (e.g., student scores in two different tests with different means and standard deviations) into Z-scores, we can determine which value is more extreme or has a higher relative standing compared to its own distribution."
      ],
      "metadata": {
        "id": "t_a_20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21:** What are the assumptions for applying the Central Limit Theorem?"
      ],
      "metadata": {
        "id": "t_q_21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A21:** The key assumptions for applying the Central Limit Theorem are:\n",
        "\n",
        "1.  **Randomization:** The samples must be drawn randomly from the population.\n",
        "2.  **Independence:** The sampled observations must be independent of each other. When sampling without replacement, the sample size should be less than 10% of the population to ensure independence.\n",
        "3.  **Sample Size:** The sample size must be \"sufficiently large.\" While there is no strict rule, a sample size of $n > 30$ is generally considered sufficient."
      ],
      "metadata": {
        "id": "t_a_21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q22:** What is the concept of expected value in a probability distribution?"
      ],
      "metadata": {
        "id": "t_q_22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A22:** The **expected value** ($E(X)$) of a random variable is the long-run average value of the variable. It's a weighted average of all possible outcomes, where the weights are the probabilities of those outcomes. For a discrete random variable, it is calculated as:\n",
        "$$ E(X) = \\sum x \\cdot P(x) $$\n",
        "It represents the mean of the probability distribution."
      ],
      "metadata": {
        "id": "t_a_22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q23:** How does a probability distribution relate to the expected outcome of a random variable?"
      ],
      "metadata": {
        "id": "t_q_23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A23:** A probability distribution provides the necessary information to calculate the expected value (or expected outcome). The distribution lists all possible values the random variable can take and their corresponding probabilities. The expected value is calculated by multiplying each possible value by its probability and summing these products. Therefore, the probability distribution is the foundation upon which the expected value is determined."
      ],
      "metadata": {
        "id": "t_a_23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Questions"
      ],
      "metadata": {
        "id": "practice_heading"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1:** Write a Python program to generate a random variable and display its value."
      ],
      "metadata": {
        "id": "p_q_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Generate a random integer between 1 and 10 (inclusive)\n",
        "random_variable_int = random.randint(1, 10)\n",
        "print(f\"Generated Random Integer: {random_variable_int}\")\n",
        "\n",
        "# Generate a random float between 0 and 1\n",
        "random_variable_float = random.random()\n",
        "print(f\"Generated Random Float: {random_variable_float}\")"
      ],
      "metadata": {
        "id": "p_a_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2:** Generate a discrete uniform distribution using Python and plot the probability mass function (PMF)."
      ],
      "metadata": {
        "id": "p_q_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define the range for the discrete uniform distribution (e.g., a die roll from 1 to 6)\n",
        "low, high = 1, 7 # high is exclusive\n",
        "outcomes = np.arange(low, high)\n",
        "\n",
        "# Calculate the PMF for each outcome\n",
        "pmf_values = randint.pmf(outcomes, low, high)\n",
        "\n",
        "# Plot the PMF\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(outcomes, pmf_values, color='skyblue')\n",
        "plt.title('PMF of a Discrete Uniform Distribution (Die Roll)')\n",
        "plt.xlabel('Outcomes')\n",
        "plt.ylabel('Probability')\n",
        "plt.xticks(outcomes)\n",
        "plt.ylim(0, 0.2)\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3:** Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution."
      ],
      "metadata": {
        "id": "p_q_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import bernoulli\n",
        "\n",
        "def bernoulli_pmf(p, k):\n",
        "    \"\"\"\n",
        "    Calculates the Probability Mass Function (PMF) of a Bernoulli distribution.\n",
        "\n",
        "    Args:\n",
        "        p (float): Probability of success (between 0 and 1).\n",
        "        k (int): Outcome (0 for failure, 1 for success).\n",
        "\n",
        "    Returns:\n",
        "        float: The probability of the outcome k.\n",
        "    \"\"\"\n",
        "    if k not in [0, 1]:\n",
        "        return 0\n",
        "    if k == 1:\n",
        "        return p\n",
        "    else: # k == 0\n",
        "        return 1 - p\n",
        "\n",
        "# Example usage:\n",
        "p_success = 0.7\n",
        "prob_of_success = bernoulli_pmf(p_success, 1)\n",
        "prob_of_failure = bernoulli_pmf(p_success, 0)\n",
        "\n",
        "print(f\"Probability of success (k=1) with p={p_success}: {prob_of_success}\")\n",
        "print(f\"Probability of failure (k=0) with p={p_success}: {prob_of_failure}\")\n",
        "\n",
        "# Using scipy for verification\n",
        "print(f\"\\nUsing scipy: P(X=1) = {bernoulli.pmf(1, p_success)}\")\n",
        "print(f\"Using scipy: P(X=0) = {bernoulli.pmf(0, p_success)}\")"
      ],
      "metadata": {
        "id": "p_a_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4:** Write a Python script to simulate a binomial distribution with $n=10$ and $p=0.5$, then plot its histogram."
      ],
      "metadata": {
        "id": "p_q_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters for the binomial distribution\n",
        "n = 10  # number of trials\n",
        "p = 0.5 # probability of success\n",
        "size = 1000 # number of simulations\n",
        "\n",
        "# Simulate the binomial distribution\n",
        "binomial_data = np.random.binomial(n, p, size)\n",
        "\n",
        "# Plot the histogram of the simulation\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(binomial_data, bins=np.arange(-0.5, n + 1.5, 1), density=True, rwidth=0.8, color='cornflowerblue', alpha=0.7)\n",
        "plt.title(f'Histogram of Binomial Distribution (n={n}, p={p})')\n",
        "plt.xlabel('Number of Successes')\n",
        "plt.ylabel('Probability')\n",
        "plt.xticks(range(n + 1))\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5:** Create a Poisson distribution and visualize it using Python."
      ],
      "metadata": {
        "id": "p_q_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import poisson\n",
        "\n",
        "# Parameter for the Poisson distribution\n",
        "lambda_param = 4  # average number of events per interval\n",
        "\n",
        "# Generate possible outcomes (number of events)\n",
        "k_values = np.arange(0, 15)\n",
        "\n",
        "# Calculate the PMF for each outcome\n",
        "pmf_values = poisson.pmf(k_values, lambda_param)\n",
        "\n",
        "# Visualize the Poisson distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(k_values, pmf_values, color='salmon')\n",
        "plt.title(f'PMF of Poisson Distribution ($\\lambda$={lambda_param})')\n",
        "plt.xlabel('Number of Events (k)')\n",
        "plt.ylabel('Probability P(X=k)')\n",
        "plt.xticks(k_values)\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6:** Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete uniform distribution."
      ],
      "metadata": {
        "id": "p_q_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define the range for the discrete uniform distribution (e.g., die roll 1-6)\n",
        "low, high = 1, 7 # high is exclusive\n",
        "outcomes = np.arange(low - 1, high + 1)\n",
        "\n",
        "# Calculate the CDF for each outcome\n",
        "cdf_values = randint.cdf(outcomes, low, high)\n",
        "\n",
        "# Plot the CDF\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.step(outcomes, cdf_values, where='post', color='green')\n",
        "plt.title('CDF of a Discrete Uniform Distribution (Die Roll)')\n",
        "plt.xlabel('Outcomes')\n",
        "plt.ylabel('Cumulative Probability P(X <= x)')\n",
        "plt.xticks(outcomes)\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7:** Generate a continuous uniform distribution using NumPy and visualize it."
      ],
      "metadata": {
        "id": "p_q_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters for the continuous uniform distribution\n",
        "low, high = 5, 20\n",
        "size = 10000\n",
        "\n",
        "# Generate data\n",
        "uniform_data = np.random.uniform(low, high, size)\n",
        "\n",
        "# Visualize the distribution with a histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(uniform_data, bins=50, density=True, color='purple', alpha=0.7, label='Histogram')\n",
        "\n",
        "# Add the PDF line for comparison\n",
        "pdf_height = 1 / (high - low)\n",
        "plt.axhline(y=pdf_height, color='r', linestyle='--', label=f'PDF (height = {pdf_height:.3f})')\n",
        "\n",
        "plt.title(f'Continuous Uniform Distribution (from {low} to {high})')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8:** Simulate data from a normal distribution and plot its histogram."
      ],
      "metadata": {
        "id": "p_q_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Parameters for the normal distribution\n",
        "mu = 50     # mean\n",
        "sigma = 10  # standard deviation\n",
        "size = 10000\n",
        "\n",
        "# Simulate data from the normal distribution\n",
        "normal_data = np.random.normal(mu, sigma, size)\n",
        "\n",
        "# Plot the histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(normal_data, bins=50, density=True, color='darkcyan', alpha=0.7, label='Simulated Data')\n",
        "\n",
        "# Plot the PDF for comparison\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "p = norm.pdf(x, mu, sigma)\n",
        "plt.plot(x, p, 'k', linewidth=2, label='Theoretical PDF')\n",
        "\n",
        "plt.title(f'Normal Distribution ($\\mu$={mu}, $\\sigma$={sigma})')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9:** Write a Python function to calculate Z-scores from a dataset and plot them."
      ],
      "metadata": {
        "id": "p_q_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_and_plot_z_scores(data):\n",
        "    \"\"\"\n",
        "    Calculates the Z-scores for a given dataset and plots their distribution.\n",
        "\n",
        "    Args:\n",
        "        data (array-like): The input dataset.\n",
        "    \"\"\"\n",
        "    # Calculate mean and standard deviation\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "\n",
        "    # Calculate Z-scores\n",
        "    z_scores = (data - mean) / std\n",
        "\n",
        "    # Print some results\n",
        "    print(f\"Original Mean: {mean:.2f}, Original Std Dev: {std:.2f}\")\n",
        "    print(f\"Z-Scores Mean: {np.mean(z_scores):.2f}, Z-Scores Std Dev: {np.std(z_scores):.2f}\")\n",
        "\n",
        "    # Plot the Z-scores\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(z_scores, bins=30, density=True, color='orange', alpha=0.7)\n",
        "    plt.title('Distribution of Z-Scores')\n",
        "    plt.xlabel('Z-Score')\n",
        "    plt.ylabel('Density')\n",
        "    plt.axvline(np.mean(z_scores), color='r', linestyle='--', label='Mean of Z-scores (~0)')\n",
        "    plt.grid(axis='y', linestyle='--')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return z_scores\n",
        "\n",
        "# Example usage with some random data\n",
        "sample_data = np.random.normal(loc=100, scale=15, size=1000)\n",
        "z_scores_result = calculate_and_plot_z_scores(sample_data)"
      ],
      "metadata": {
        "id": "p_a_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10:** Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution."
      ],
      "metadata": {
        "id": "p_q_10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Let's use a uniform distribution (which is non-normal)\n",
        "population = np.random.uniform(0, 100, 100000)\n",
        "\n",
        "# Parameters for the simulation\n",
        "sample_size = 50      # Size of each sample\n",
        "num_samples = 1000    # Number of samples to take\n",
        "\n",
        "# Store the means of each sample\n",
        "sample_means = []\n",
        "\n",
        "# Take samples and calculate their means\n",
        "for _ in range(num_samples):\n",
        "    sample = np.random.choice(population, size=sample_size)\n",
        "    sample_means.append(np.mean(sample))\n",
        "\n",
        "# Plot the original population distribution and the sampling distribution of the mean\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot 1: Original Population\n",
        "ax1.hist(population, bins=50, color='gray', density=True)\n",
        "ax1.set_title('Original Population Distribution (Uniform)')\n",
        "ax1.set_xlabel('Value')\n",
        "ax1.set_ylabel('Density')\n",
        "\n",
        "# Plot 2: Sampling Distribution of the Mean\n",
        "ax2.hist(sample_means, bins=30, color='royalblue', density=True)\n",
        "ax2.set_title('Sampling Distribution of the Mean (CLT in action)')\n",
        "ax2.set_xlabel('Sample Mean')\n",
        "ax2.set_ylabel('Density')\n",
        "\n",
        "plt.suptitle(f'Central Limit Theorem Demonstration (Sample Size = {sample_size})')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11:** Simulate multiple samples from a normal distribution and verify the Central Limit Theorem."
      ],
      "metadata": {
        "id": "p_q_11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Population is already normal\n",
        "mu, sigma = 100, 20\n",
        "population = np.random.normal(mu, sigma, 100000)\n",
        "\n",
        "# Parameters for the simulation\n",
        "sample_size = 30\n",
        "num_samples = 1000\n",
        "\n",
        "sample_means = []\n",
        "for _ in range(num_samples):\n",
        "    sample = np.random.choice(population, size=sample_size)\n",
        "    sample_means.append(np.mean(sample))\n",
        "\n",
        "# According to CLT, the mean of sample means should be close to the population mean (mu)\n",
        "# and the standard deviation of sample means (standard error) should be sigma / sqrt(n)\n",
        "mean_of_means = np.mean(sample_means)\n",
        "std_of_means = np.std(sample_means)\n",
        "theoretical_std_error = sigma / np.sqrt(sample_size)\n",
        "\n",
        "print(f\"Population Mean (μ): {mu}\")\n",
        "print(f\"Mean of Sample Means: {mean_of_means:.2f}\")\n",
        "print(f\"\\nPopulation Std Dev (σ): {sigma}\")\n",
        "print(f\"Theoretical Standard Error (σ/√n): {theoretical_std_error:.2f}\")\n",
        "print(f\"Actual Std Dev of Sample Means: {std_of_means:.2f}\")\n",
        "\n",
        "# Plotting the distribution of sample means\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(sample_means, bins=30, density=True, color='forestgreen', alpha=0.7, label='Distribution of Sample Means')\n",
        "plt.title('Sampling Distribution from a Normal Population')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12:** Write a Python function to calculate and plot the standard normal distribution (mean = 0, std = 1)."
      ],
      "metadata": {
        "id": "p_q_12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_standard_normal_distribution():\n",
        "    \"\"\"\n",
        "    Calculates and plots the PDF of the Standard Normal Distribution.\n",
        "    \"\"\"\n",
        "    # Define the range for the x-axis\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "\n",
        "    # Calculate the PDF using scipy.stats.norm\n",
        "    # For standard normal, mean=0 and std=1\n",
        "    pdf_values = norm.pdf(x, loc=0, scale=1)\n",
        "\n",
        "    # Plot the PDF\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, pdf_values, color='black', label='PDF')\n",
        "    plt.title('Standard Normal Distribution ($\\mu=0, \\sigma=1$)')\n",
        "    plt.xlabel('Z-score')\n",
        "    plt.ylabel('Density')\n",
        "    plt.grid(True, linestyle='--')\n",
        "\n",
        "    # Shade areas for 1, 2, and 3 standard deviations\n",
        "    plt.fill_between(x, pdf_values, where=(x > -1) & (x < 1), color='skyblue', alpha=0.5, label='68%')\n",
        "    plt.fill_between(x, pdf_values, where=(x > -2) & (x < 2), color='royalblue', alpha=0.3, label='95%')\n",
        "    plt.fill_between(x, pdf_values, where=(x > -3) & (x < 3), color='steelblue', alpha=0.2, label='99.7%')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to generate the plot\n",
        "plot_standard_normal_distribution()"
      ],
      "metadata": {
        "id": "p_a_12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13:** Generate random variables and calculate their corresponding probabilities using the binomial distribution."
      ],
      "metadata": {
        "id": "p_q_13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import binom\n",
        "\n",
        "# Parameters\n",
        "n = 20  # number of trials (e.g., flipping a coin 20 times)\n",
        "p = 0.4 # probability of success (e.g., getting heads)\n",
        "\n",
        "# Let's calculate the probability of a few specific outcomes\n",
        "k_values = [5, 8, 10] # number of successes we are interested in\n",
        "\n",
        "for k in k_values:\n",
        "    # Calculate the probability P(X=k) using the PMF\n",
        "    probability = binom.pmf(k, n, p)\n",
        "    print(f\"The probability of getting exactly {k} successes in {n} trials is {probability:.4f}\")\n",
        "\n",
        "# Let's also calculate a cumulative probability, e.g., P(X <= 7)\n",
        "k_cumulative = 7\n",
        "cum_prob = binom.cdf(k_cumulative, n, p)\n",
        "print(f\"\\nThe probability of getting {k_cumulative} or fewer successes is {cum_prob:.4f}\")"
      ],
      "metadata": {
        "id": "p_a_13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14:** Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal distribution."
      ],
      "metadata": {
        "id": "p_q_14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "def analyze_z_score(data_point, mean, std_dev):\n",
        "    \"\"\"\n",
        "    Calculates the Z-score and finds its percentile in the standard normal distribution.\n",
        "    \"\"\"\n",
        "    # Calculate Z-score\n",
        "    z_score = (data_point - mean) / std_dev\n",
        "    print(f\"Data Point: {data_point}\")\n",
        "    print(f\"Mean: {mean}, Standard Deviation: {std_dev}\")\n",
        "    print(f\"Calculated Z-score: {z_score:.2f}\")\n",
        "\n",
        "    # Find the cumulative probability (percentile)\n",
        "    percentile = norm.cdf(z_score) * 100\n",
        "    print(f\"This Z-score corresponds to the {percentile:.2f}th percentile.\")\n",
        "\n",
        "    if z_score > 2:\n",
        "        print(\"This is an unusually high value (more than 2 std dev above the mean).\")\n",
        "    elif z_score < -2:\n",
        "        print(\"This is an unusually low value (more than 2 std dev below the mean).\")\n",
        "    else:\n",
        "        print(\"This value is within the typical range (within 2 std dev of the mean).\")\n",
        "\n",
        "# Example: Test scores are normally distributed with a mean of 75 and a std dev of 10.\n",
        "# A student scored 95. Let's analyze their score.\n",
        "student_score = 95\n",
        "test_mean = 75\n",
        "test_std = 10\n",
        "\n",
        "analyze_z_score(student_score, test_mean, test_std)"
      ],
      "metadata": {
        "id": "p_a_14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15:** Implement hypothesis testing using Z-statistics for a sample dataset."
      ],
      "metadata": {
        "id": "p_q_15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Scenario: A factory produces bolts with a known standard deviation of length of 0.5mm.\n",
        "# The target length is 100mm. We take a sample of 50 bolts to check if the machine is calibrated correctly.\n",
        "\n",
        "# H0 (Null Hypothesis): The population mean (μ) is 100mm.\n",
        "# Ha (Alternative Hypothesis): The population mean (μ) is not 100mm.\n",
        "\n",
        "# Population parameters\n",
        "pop_mean_h0 = 100\n",
        "pop_std_dev = 0.5\n",
        "\n",
        "# Sample data (let's generate some sample data)\n",
        "np.random.seed(42)\n",
        "sample_size = 50\n",
        "sample_data = np.random.normal(loc=100.15, scale=pop_std_dev, size=sample_size)\n",
        "sample_mean = np.mean(sample_data)\n",
        "\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Calculate the Z-statistic\n",
        "standard_error = pop_std_dev / np.sqrt(sample_size)\n",
        "z_statistic = (sample_mean - pop_mean_h0) / standard_error\n",
        "\n",
        "print(f\"Z-statistic: {z_statistic:.2f}\")\n",
        "\n",
        "# Calculate the p-value (for a two-tailed test)\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_statistic)))\n",
        "\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Make a decision\n",
        "if p_value < alpha:\n",
        "    print(f\"Decision: Reject the null hypothesis (since p-value < {alpha}).\")\n",
        "    print(\"Conclusion: There is significant evidence that the machine is not calibrated correctly.\")\n",
        "else:\n",
        "    print(f\"Decision: Fail to reject the null hypothesis (since p-value >= {alpha}).\")\n",
        "    print(\"Conclusion: There is not enough evidence to say the machine is uncalibrated.\")"
      ],
      "metadata": {
        "id": "p_a_15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16:** Create a confidence interval for a dataset using Python and interpret the result."
      ],
      "metadata": {
        "id": "p_q_16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Let's assume we have a sample of student IQ scores\n",
        "iq_scores = np.array([105, 98, 110, 102, 95, 115, 108, 92, 100, 112, 103, 99])\n",
        "\n",
        "# Parameters\n",
        "confidence_level = 0.95\n",
        "sample_mean = np.mean(iq_scores)\n",
        "sample_std = np.std(iq_scores, ddof=1) # Use ddof=1 for sample std dev\n",
        "n = len(iq_scores)\n",
        "\n",
        "# Calculate the standard error of the mean\n",
        "std_error = sample_std / np.sqrt(n)\n",
        "\n",
        "# Since the population std dev is unknown and n < 30, we should technically use a t-distribution.\n",
        "# However, the question asks about Z-scores, so we'll proceed assuming Z is appropriate (e.g., if population std dev were known).\n",
        "# For a more robust solution, stats.t.interval is better.\n",
        "\n",
        "# Using Z-distribution for demonstration\n",
        "# Find the critical value (Z-score) for the given confidence level\n",
        "z_critical = stats.norm.ppf((1 + confidence_level) / 2)\n",
        "\n",
        "# Calculate the margin of error\n",
        "margin_of_error = z_critical * std_error\n",
        "\n",
        "# Calculate the confidence interval\n",
        "ci_lower = sample_mean - margin_of_error\n",
        "ci_upper = sample_mean + margin_of_error\n",
        "\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"{confidence_level*100}% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
        "\n",
        "print(\"\\n--- Using the more appropriate t-distribution for comparison ---\")\n",
        "ci_t = stats.t.interval(confidence_level, df=n-1, loc=sample_mean, scale=std_error)\n",
        "print(f\"{confidence_level*100}% T-based Confidence Interval: ({ci_t[0]:.2f}, {ci_t[1]:.2f})\")\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"We are {confidence_level*100}% confident that the true average IQ score of the population from which this sample was drawn lies between {ci_lower:.2f} and {ci_upper:.2f}.\")"
      ],
      "metadata": {
        "id": "p_a_16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17:** Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean."
      ],
      "metadata": {
        "id": "p_q_17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# True population parameters (we know these because we're generating the data)\n",
        "true_pop_mean = 150\n",
        "true_pop_std = 25\n",
        "\n",
        "# Generate a sample from this population\n",
        "sample_size = 40\n",
        "sample_data = np.random.normal(loc=true_pop_mean, scale=true_pop_std, size=sample_size)\n",
        "\n",
        "# Now, pretend we only have the sample_data and don't know the true parameters\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_std = np.std(sample_data, ddof=1)\n",
        "\n",
        "# Calculate the 99% confidence interval\n",
        "confidence_level = 0.99\n",
        "std_error = sample_std / np.sqrt(sample_size)\n",
        "\n",
        "# We can use Z-score here since n > 30\n",
        "z_critical = stats.norm.ppf((1 + confidence_level) / 2)\n",
        "margin_of_error = z_critical * std_error\n",
        "ci_lower = sample_mean - margin_of_error\n",
        "ci_upper = sample_mean + margin_of_error\n",
        "\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"{confidence_level*100}% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
        "print(f\"Does our interval contain the true population mean of {true_pop_mean}? {'Yes' if ci_lower <= true_pop_mean <= ci_upper else 'No'}\")\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"Based on our sample, we are 99% confident that the true population mean lies somewhere between {ci_lower:.2f} and {ci_upper:.2f}. \",\n",
        "      \"Since we know the true mean is 150, we can see that our confidence interval correctly captured it.\")"
      ],
      "metadata": {
        "id": "p_a_17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18:** Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution."
      ],
      "metadata": {
        "id": "p_q_18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Define parameters for a normal distribution\n",
        "mean = 100\n",
        "std_dev = 15\n",
        "\n",
        "# Create a range of x values\n",
        "x_values = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 1000)\n",
        "\n",
        "# Calculate the PDF for each x value\n",
        "pdf_values = norm.pdf(x_values, loc=mean, scale=std_dev)\n",
        "\n",
        "# Visualize the PDF\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x_values, pdf_values, color='crimson', lw=2)\n",
        "plt.title(f'PDF of Normal Distribution ($\\mu$={mean}, $\\sigma$={std_dev})')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True, linestyle='--')\n",
        "plt.axvline(mean, color='k', linestyle=':', label=f'Mean = {mean}')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19:** Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution."
      ],
      "metadata": {
        "id": "p_q_19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import poisson\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Scenario: A customer service center receives an average of 10 calls per hour.\n",
        "lambda_param = 10\n",
        "\n",
        "# We want to calculate the probability of receiving 8 or fewer calls in an hour.\n",
        "k = 8\n",
        "cdf_value = poisson.cdf(k, lambda_param)\n",
        "\n",
        "print(f\"The average number of calls per hour (λ) is {lambda_param}.\")\n",
        "print(f\"The probability of receiving {k} or fewer calls in an hour is P(X <= {k}) = {cdf_value:.4f}\")\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"There is a {cdf_value*100:.2f}% chance that the service center will receive 8 or fewer calls in any given hour.\")\n",
        "\n",
        "# Visualize the CDF\n",
        "k_values = np.arange(0, 25)\n",
        "cdf_values = poisson.cdf(k_values, mu=lambda_param)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.step(k_values, cdf_values, where='post', color='darkmagenta')\n",
        "plt.title(f'CDF of Poisson Distribution ($\\lambda$={lambda_param})')\n",
        "plt.xlabel('Number of Calls (k)')\n",
        "plt.ylabel('Cumulative Probability P(X <= k)')\n",
        "plt.grid(True, linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20:** Simulate a random variable using a continuous uniform distribution and calculate its expected value."
      ],
      "metadata": {
        "id": "p_q_20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Parameters for the continuous uniform distribution\n",
        "a = 10  # lower bound\n",
        "b = 50  # upper bound\n",
        "\n",
        "# The theoretical expected value (mean) of a continuous uniform distribution is (a + b) / 2\n",
        "theoretical_expected_value = (a + b) / 2\n",
        "print(f\"Theoretical Expected Value: {theoretical_expected_value}\")\n",
        "\n",
        "# Simulate a large number of random variables from this distribution\n",
        "num_simulations = 1000000\n",
        "simulated_data = np.random.uniform(a, b, num_simulations)\n",
        "\n",
        "# Calculate the sample mean (which is our estimate of the expected value)\n",
        "sample_mean = np.mean(simulated_data)\n",
        "print(f\"Sample Mean from {num_simulations} simulations: {sample_mean:.4f}\")\n",
        "\n",
        "print(\"\\nAs you can see, the sample mean from the simulation is very close to the theoretical expected value, as predicted by the law of large numbers.\")"
      ],
      "metadata": {
        "id": "p_a_20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21:** Write a Python program to compare the standard deviations of two datasets and visualize the difference."
      ],
      "metadata": {
        "id": "p_q_21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate two datasets with different standard deviations\n",
        "np.random.seed(10)\n",
        "data1 = np.random.normal(loc=50, scale=5, size=500)  # Lower standard deviation\n",
        "data2 = np.random.normal(loc=50, scale=15, size=500) # Higher standard deviation\n",
        "\n",
        "# Calculate the standard deviations\n",
        "std1 = np.std(data1)\n",
        "std2 = np.std(data2)\n",
        "\n",
        "print(f\"Standard Deviation of Dataset 1: {std1:.2f}\")\n",
        "print(f\"Standard Deviation of Dataset 2: {std2:.2f}\")\n",
        "\n",
        "# Visualize the difference using histograms and boxplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Histograms\n",
        "ax1.hist(data1, bins=30, alpha=0.7, label=f'Dataset 1 (std={std1:.2f})', color='c')\n",
        "ax1.hist(data2, bins=30, alpha=0.7, label=f'Dataset 2 (std={std2:.2f})', color='m')\n",
        "ax1.set_title('Histograms of Two Datasets')\n",
        "ax1.set_xlabel('Value')\n",
        "ax1.set_ylabel('Frequency')\n",
        "ax1.legend()\n",
        "\n",
        "# Boxplots\n",
        "ax2.boxplot([data1, data2], labels=['Dataset 1', 'Dataset 2'])\n",
        "ax2.set_title('Boxplots of Two Datasets')\n",
        "ax2.set_ylabel('Value')\n",
        "\n",
        "plt.suptitle('Comparing Standard Deviations')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q22:** Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution."
      ],
      "metadata": {
        "id": "p_q_22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import iqr\n",
        "\n",
        "# Generate data from a normal distribution\n",
        "data = np.random.normal(loc=100, scale=20, size=1000)\n",
        "\n",
        "# Calculate the range\n",
        "# Range = Maximum value - Minimum value\n",
        "data_range = np.ptp(data)\n",
        "# Equivalent to: data_range = np.max(data) - np.min(data)\n",
        "\n",
        "# Calculate the Interquartile Range (IQR)\n",
        "# IQR = 75th percentile (Q3) - 25th percentile (Q1)\n",
        "data_iqr_scipy = iqr(data)\n",
        "# Equivalent to:\n",
        "# q3, q1 = np.percentile(data, [75, 25])\n",
        "# data_iqr_numpy = q3 - q1\n",
        "\n",
        "print(f\"Dataset generated from a normal distribution.\")\n",
        "print(f\"Range (Max - Min): {data_range:.2f}\")\n",
        "print(f\"Interquartile Range (IQR): {data_iqr_scipy:.2f}\")\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"The range gives the total spread of the data, but is sensitive to outliers.\")\n",
        "print(\"The IQR gives the spread of the middle 50% of the data and is robust to outliers.\")"
      ],
      "metadata": {
        "id": "p_a_22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q23:** Implement Z-score normalization on a dataset and visualize its transformation."
      ],
      "metadata": {
        "id": "p_q_23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Generate some non-standard normal data\n",
        "original_data = np.random.normal(loc=500, scale=50, size=1000)\n",
        "\n",
        "# Perform Z-score normalization (Standardization)\n",
        "mean_orig = np.mean(original_data)\n",
        "std_orig = np.std(original_data)\n",
        "normalized_data = (original_data - mean_orig) / std_orig\n",
        "\n",
        "print(f\"Original Data: Mean={np.mean(original_data):.2f}, Std Dev={np.std(original_data):.2f}\")\n",
        "print(f\"Normalized Data: Mean={np.mean(normalized_data):.2f}, Std Dev={np.std(normalized_data):.2f}\")\n",
        "\n",
        "# Visualize the transformation\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Before Normalization\n",
        "ax1.hist(original_data, bins=30, color='skyblue', density=True)\n",
        "ax1.set_title('Before Z-Score Normalization')\n",
        "ax1.set_xlabel('Value')\n",
        "ax1.set_ylabel('Density')\n",
        "\n",
        "# After Normalization\n",
        "ax2.hist(normalized_data, bins=30, color='salmon', density=True)\n",
        "x = np.linspace(-4, 4, 100)\n",
        "ax2.plot(x, norm.pdf(x), 'k--', label='Standard Normal PDF') # Overlay standard normal PDF\n",
        "ax2.set_title('After Z-Score Normalization')\n",
        "ax2.set_xlabel('Z-Score')\n",
        "ax2.set_ylabel('Density')\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_a_23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q24:** Write a Python function to calculate the skewness and kurtosis of a dataset generated from a normal distribution."
      ],
      "metadata": {
        "id": "p_a_24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "import numpy as np\n",
        "\n",
        "def analyze_shape(data):\n",
        "    \"\"\"\n",
        "    Calculates and interprets the skewness and kurtosis of a dataset.\n",
        "    \"\"\"\n",
        "    # Calculate skewness and kurtosis\n",
        "    data_skewness = skew(data)\n",
        "    data_kurtosis = kurtosis(data) # Fisher's kurtosis (normal=0)\n",
        "\n",
        "    print(f\"Skewness: {data_skewness:.4f}\")\n",
        "    print(f\"Kurtosis: {data_kurtosis:.4f}\")\n",
        "\n",
        "    # Interpretation\n",
        "    print(\"\\n--- Interpretation ---\")\n",
        "    if -0.5 < data_skewness < 0.5:\n",
        "        print(\"Skewness is close to 0, indicating the data is fairly symmetrical.\")\n",
        "    elif data_skewness > 0.5:\n",
        "        print(\"Data is positively skewed (right-skewed).\")\n",
        "    else:\n",
        "        print(\"Data is negatively skewed (left-skewed).\")\n",
        "\n",
        "    if -0.5 < data_kurtosis < 0.5:\n",
        "        print(\"Kurtosis is close to 0, indicating a mesokurtic distribution (similar to normal).\" )\n",
        "    elif data_kurtosis > 0.5:\n",
        "        print(\"Kurtosis is > 0, indicating a leptokurtic distribution (heavier tails, sharper peak).\")\n",
        "    else:\n",
        "        print(\"Kurtosis is < 0, indicating a platykurtic distribution (lighter tails, flatter peak).\")\n",
        "\n",
        "# Generate data from a normal distribution\n",
        "normal_data = np.random.normal(size=5000)\n",
        "\n",
        "print(\"Analyzing a dataset from a Normal Distribution:\")\n",
        "analyze_shape(normal_data)\n",
        "\n",
        "# For a normal distribution, we expect skewness and kurtosis to be close to 0."
      ],
      "metadata": {
        "id": "9RaoCoKpfEqv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}